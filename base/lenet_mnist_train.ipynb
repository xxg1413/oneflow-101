{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oneflow as flow\n",
    "import oneflow.typing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet(data, train=False):\n",
    "    initializer = flow.truncated_normal(0.1)\n",
    "    conv1 = flow.layers.conv2d(\n",
    "        data,\n",
    "        32,\n",
    "        5,\n",
    "        padding=\"SAME\",\n",
    "        activation=flow.nn.relu,\n",
    "        name=\"conv1\",\n",
    "        kernel_initializer=initializer,\n",
    "    )\n",
    "    pool1 = flow.nn.max_pool2d(\n",
    "        conv1, ksize=2, strides=2, padding=\"SAME\", name=\"pool1\", data_format=\"NCHW\"\n",
    "    )\n",
    "    conv2 = flow.layers.conv2d(\n",
    "        pool1,\n",
    "        64,\n",
    "        5,\n",
    "        padding=\"SAME\",\n",
    "        activation=flow.nn.relu,\n",
    "        name=\"conv2\",\n",
    "        kernel_initializer=initializer,\n",
    "    )\n",
    "    pool2 = flow.nn.max_pool2d(\n",
    "        conv2, ksize=2, strides=2, padding=\"SAME\", name=\"pool2\", data_format=\"NCHW\"\n",
    "    )\n",
    "    reshape = flow.reshape(pool2, [pool2.shape[0], -1])\n",
    "    hidden = flow.layers.dense(\n",
    "        reshape,\n",
    "        512,\n",
    "        activation=flow.nn.relu,\n",
    "        kernel_initializer=initializer,\n",
    "        name=\"dense1\",\n",
    "    )\n",
    "    if train:\n",
    "        hidden = flow.nn.dropout(hidden, rate=0.5, name=\"dropout\")\n",
    "    return flow.layers.dense(hidden, 10, kernel_initializer=initializer, name=\"dense2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#шонч╗Г\n",
    "@flow.global_function(type=\"train\")\n",
    "def train_job(\n",
    "    images: tp.Numpy.Placeholder((BATCH_SIZE, 1, 28, 28), dtype=flow.float),\n",
    "    labels: tp.Numpy.Placeholder((BATCH_SIZE,), dtype=flow.int32),\n",
    ") -> tp.Numpy:\n",
    "    with flow.scope.placement(\"gpu\", \"0:0\"):\n",
    "        logits = lenet(images, train=True)\n",
    "        loss = flow.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels, logits, name=\"softmax_loss\"\n",
    "        )\n",
    "\n",
    "    lr_scheduler = flow.optimizer.PiecewiseConstantScheduler([], [0.1])\n",
    "    flow.optimizer.SGD(lr_scheduler, momentum=0).minimize(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.config.gpu_device_num(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = flow.train.CheckPoint()\n",
    "check_point.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mnist.npz already exist, path: ./mnist.npz\n"
     ]
    }
   ],
   "source": [
    "   (train_images, train_labels), (test_images, test_labels) = flow.data.load_mnist(\n",
    "        BATCH_SIZE, BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4304714\n",
      "1.1816862\n",
      "0.42266613\n",
      "0.3483231\n",
      "0.23331955\n",
      "0.24564157\n",
      "0.2680526\n",
      "0.23363036\n",
      "0.24496683\n",
      "0.12906724\n",
      "0.2550579\n",
      "0.081116155\n",
      "0.17715953\n",
      "0.11035161\n",
      "0.10084554\n",
      "0.1626459\n",
      "0.19110979\n",
      "0.07018511\n",
      "0.17930636\n",
      "0.047810417\n",
      "0.083348\n",
      "0.20465498\n",
      "0.12702033\n",
      "0.19150552\n",
      "0.13384208\n",
      "0.064903006\n",
      "0.12788668\n",
      "0.18227144\n",
      "0.084598154\n",
      "0.08224721\n",
      "0.07146042\n",
      "0.1441957\n",
      "0.128395\n",
      "0.026951086\n",
      "0.040065285\n",
      "0.16551672\n",
      "0.095258825\n",
      "0.09995119\n",
      "0.08750807\n",
      "0.06958059\n",
      "0.071375236\n",
      "0.04716398\n",
      "0.029938051\n",
      "0.04587161\n",
      "0.052131426\n",
      "0.11289297\n",
      "0.08389154\n",
      "0.05752547\n",
      "0.11423657\n",
      "0.061923917\n",
      "0.089823395\n",
      "0.069212444\n",
      "0.082397126\n",
      "0.097064696\n",
      "0.049636483\n",
      "0.03532106\n",
      "0.09834539\n",
      "0.14888397\n",
      "0.053040933\n",
      "0.06039332\n",
      "0.054609302\n",
      "0.0954063\n",
      "0.057975076\n",
      "0.054392677\n",
      "0.055142924\n",
      "0.11056551\n",
      "0.090062626\n",
      "0.024433298\n",
      "0.07084119\n",
      "0.051630173\n",
      "0.082517155\n",
      "0.017306574\n",
      "0.017913405\n",
      "0.05696125\n",
      "0.034146875\n",
      "0.07452651\n",
      "0.05722817\n",
      "0.040682297\n",
      "0.1078422\n",
      "0.04957526\n",
      "0.024497861\n",
      "0.09798545\n",
      "0.07414208\n",
      "0.08338656\n",
      "0.07315427\n",
      "0.013292475\n",
      "0.02770225\n",
      "0.090204656\n",
      "0.05740983\n",
      "0.08488141\n",
      "0.07727215\n",
      "0.026145175\n",
      "0.016773019\n",
      "0.04133862\n",
      "0.015543351\n",
      "0.09474301\n",
      "0.050046902\n",
      "0.047057744\n",
      "0.028729424\n",
      "0.03704846\n",
      "0.06835562\n",
      "0.0033479014\n",
      "0.022274531\n",
      "0.069011085\n",
      "0.06001241\n",
      "0.066765524\n",
      "0.0421812\n",
      "0.061305426\n",
      "0.0735479\n",
      "0.041723393\n",
      "0.031572737\n",
      "0.08157195\n",
      "0.029646492\n",
      "0.04771279\n",
      "0.029602164\n",
      "0.020640492\n",
      "0.04280964\n",
      "0.060924757\n",
      "0.035845134\n",
      "0.03723676\n",
      "0.026597362\n",
      "0.008486545\n",
      "0.021541912\n",
      "0.023704283\n",
      "0.014173803\n",
      "0.06511264\n",
      "0.05366507\n",
      "0.020466767\n",
      "0.06218607\n",
      "0.046030436\n",
      "0.10057471\n",
      "0.008496429\n",
      "0.01240918\n",
      "0.056713037\n",
      "0.034186825\n",
      "0.0227741\n",
      "0.055716157\n",
      "0.05317337\n",
      "0.051585328\n",
      "0.03752151\n",
      "0.038380507\n",
      "0.062143635\n",
      "0.015312374\n",
      "0.043512583\n",
      "0.062623374\n",
      "0.0073535596\n",
      "0.012949196\n",
      "0.10401637\n",
      "0.03832908\n",
      "0.084453695\n",
      "0.04474578\n",
      "0.048145384\n",
      "0.013492075\n",
      "0.01682893\n",
      "0.025672417\n",
      "0.1309005\n",
      "0.027659483\n",
      "0.04563067\n",
      "0.016866473\n",
      "0.04000383\n",
      "0.032047175\n",
      "0.008209233\n",
      "0.017694194\n",
      "0.03230608\n",
      "0.031519935\n",
      "0.10490057\n",
      "0.043992124\n",
      "0.04611356\n",
      "0.09797346\n",
      "0.01660924\n",
      "0.009154989\n",
      "0.021630416\n",
      "0.01984809\n",
      "0.06523165\n",
      "0.049012065\n",
      "0.00421256\n",
      "0.021537013\n",
      "0.05194979\n",
      "0.04060464\n",
      "0.039700866\n",
      "0.0434542\n",
      "0.030618634\n",
      "0.009697206\n",
      "0.021954892\n",
      "0.008434068\n",
      "0.05133516\n",
      "0.013820643\n",
      "0.02890672\n",
      "0.019009238\n",
      "0.0077752084\n",
      "0.080670856\n",
      "0.0049776672\n",
      "0.010644381\n",
      "0.012748313\n",
      "0.021716278\n",
      "0.051331736\n",
      "0.017876312\n",
      "0.029481018\n",
      "0.061039314\n",
      "0.0055561815\n",
      "0.022827305\n",
      "0.07308656\n",
      "0.015285938\n",
      "0.047392964\n",
      "0.020228308\n",
      "0.008989347\n",
      "0.02845015\n",
      "0.026314583\n",
      "0.034566455\n",
      "0.02916606\n",
      "0.04378896\n",
      "0.065295205\n",
      "0.055971414\n",
      "0.041830596\n",
      "0.009178646\n",
      "0.03109621\n",
      "0.019992787\n",
      "0.044382647\n",
      "0.014696991\n",
      "0.032400742\n",
      "0.03257648\n",
      "0.015713353\n",
      "0.017806115\n",
      "0.042614833\n",
      "0.0410645\n",
      "0.060314123\n",
      "0.040805336\n",
      "0.027086873\n",
      "0.018343896\n",
      "0.03354468\n",
      "0.019240377\n",
      "0.034070805\n",
      "0.009445162\n",
      "0.078093916\n",
      "0.015627494\n",
      "0.0054020076\n",
      "0.023987556\n",
      "0.031075893\n",
      "0.042877264\n",
      "0.029050238\n",
      "0.035950564\n",
      "0.010993064\n",
      "0.011900381\n",
      "0.01839666\n",
      "0.012736674\n",
      "0.053866148\n",
      "0.026965223\n",
      "0.014533646\n",
      "0.01384328\n",
      "0.030274773\n",
      "0.02568439\n",
      "0.02608209\n",
      "0.037321206\n",
      "0.027987562\n",
      "0.005148935\n",
      "0.07646121\n",
      "0.0114079425\n",
      "0.027494892\n",
      "0.014940748\n",
      "0.011583849\n",
      "0.025644302\n",
      "0.10058569\n",
      "0.032248\n",
      "0.033650186\n",
      "0.03935461\n",
      "0.00926066\n",
      "0.049140997\n",
      "0.07657902\n",
      "0.016423408\n",
      "0.017268145\n",
      "0.048800383\n",
      "0.0055840136\n",
      "0.005817215\n",
      "0.012783255\n",
      "0.003217824\n",
      "0.041569248\n",
      "0.01374572\n",
      "0.016160049\n",
      "0.018335968\n",
      "0.09065154\n",
      "0.022829235\n",
      "0.0009282308\n",
      "0.030566273\n",
      "0.028266482\n",
      "0.007192257\n",
      "0.024189614\n",
      "0.016623467\n",
      "0.0065051173\n",
      "0.03578821\n",
      "0.0322402\n",
      "0.0181181\n",
      "0.023060365\n",
      "0.02200354\n",
      "0.09717706\n",
      "0.0037755715\n",
      "0.0022983884\n",
      "0.023002481\n",
      "0.04145449\n",
      "0.020957343\n",
      "0.016148767\n",
      "0.06148918\n",
      "0.047279358\n",
      "0.011256944\n",
      "0.0024895975\n",
      "0.0036071409\n",
      "0.04322079\n",
      "0.03611265\n",
      "0.03380614\n",
      "0.021181105\n",
      "0.045161005\n",
      "0.03922824\n",
      "0.033472452\n",
      "0.003748458\n",
      "0.0029435987\n",
      "0.004611944\n",
      "0.10498295\n",
      "0.06525194\n",
      "0.012385216\n",
      "0.123222105\n",
      "0.0040143486\n",
      "0.00669922\n",
      "0.014069184\n",
      "0.00561503\n",
      "0.058049463\n",
      "0.035533696\n",
      "0.001354349\n",
      "0.05182132\n",
      "0.022184074\n",
      "0.03262916\n",
      "0.023365699\n",
      "0.042043805\n",
      "0.024608748\n",
      "0.006788795\n",
      "0.06451785\n",
      "0.018814996\n",
      "0.028478825\n",
      "0.03914716\n",
      "0.014021657\n",
      "0.061188\n",
      "0.0077684484\n",
      "0.024130173\n",
      "0.002124482\n",
      "0.0043385276\n",
      "0.026788104\n",
      "0.0028301755\n",
      "0.08041761\n",
      "0.012036299\n",
      "0.01230609\n",
      "0.01277964\n",
      "0.0018641935\n",
      "0.015170064\n",
      "0.03402921\n",
      "0.01130569\n",
      "0.07447305\n",
      "0.009545085\n",
      "0.010603721\n",
      "0.015149967\n",
      "0.048280295\n",
      "0.014187792\n",
      "0.018900631\n",
      "0.009206049\n",
      "0.022454254\n",
      "0.014929955\n",
      "0.03283319\n",
      "0.017708879\n",
      "0.07082957\n",
      "0.04253623\n",
      "0.033779137\n",
      "0.016728435\n",
      "0.02703446\n",
      "0.05421114\n",
      "0.0035469767\n",
      "0.014795648\n",
      "0.01795493\n",
      "0.0004898018\n",
      "0.0086702565\n",
      "0.012145533\n",
      "0.028118456\n",
      "0.008031723\n",
      "0.023567142\n",
      "0.004913555\n",
      "0.012410115\n",
      "0.009699323\n",
      "0.048361443\n",
      "0.010287399\n",
      "0.00080024725\n",
      "0.03281687\n",
      "0.04221649\n",
      "0.045322556\n",
      "0.009126851\n",
      "0.0038753569\n",
      "0.00486372\n",
      "0.05493057\n",
      "0.011139737\n",
      "0.0024173039\n",
      "0.043836996\n",
      "0.011091659\n",
      "0.03445624\n",
      "0.009403863\n",
      "0.027993364\n",
      "0.054437593\n",
      "0.000312192\n",
      "0.005543392\n",
      "0.015192286\n",
      "0.0005643472\n",
      "0.0049047368\n",
      "0.012421579\n",
      "0.02513418\n",
      "0.010693013\n",
      "0.039403524\n",
      "0.018284203\n",
      "0.01982782\n",
      "0.0063328333\n",
      "0.04046164\n",
      "0.013799753\n",
      "0.018063677\n",
      "0.012898271\n",
      "0.058583185\n",
      "0.02014133\n",
      "0.025435377\n",
      "0.022171589\n",
      "0.0022650913\n",
      "0.0113657\n",
      "0.012877058\n",
      "0.0057567614\n",
      "0.044468198\n",
      "0.067860834\n",
      "0.005176952\n",
      "0.00628515\n",
      "0.011706168\n",
      "0.018366365\n",
      "0.009322781\n",
      "0.03892129\n",
      "0.0042876946\n",
      "0.016964464\n",
      "0.010510871\n",
      "0.0054711085\n",
      "0.03804053\n",
      "0.037934877\n",
      "0.016935512\n",
      "0.0009935222\n",
      "0.007416684\n",
      "0.027335536\n",
      "0.03453615\n",
      "0.015722532\n",
      "0.0012491988\n",
      "0.03603\n",
      "0.0018914955\n",
      "0.03782921\n",
      "0.06090054\n",
      "0.016312573\n",
      "0.007279599\n",
      "0.026389485\n",
      "0.0064464104\n",
      "0.005647139\n",
      "0.025998686\n",
      "0.010383937\n",
      "0.0060297363\n",
      "0.011195702\n",
      "0.00729349\n",
      "0.020988578\n",
      "0.0017074926\n",
      "0.0086804405\n",
      "0.0027127063\n",
      "0.002994162\n",
      "0.046015576\n",
      "0.032501932\n",
      "0.030284284\n",
      "0.008555435\n",
      "0.033134148\n",
      "0.0015114766\n",
      "0.0033421116\n",
      "0.0036382666\n",
      "0.04916693\n",
      "0.014243091\n",
      "0.007949732\n",
      "0.007608825\n",
      "0.010537994\n",
      "0.02410771\n",
      "0.0046006963\n",
      "0.029992716\n",
      "0.0051726038\n",
      "0.0028751246\n",
      "0.02568783\n",
      "0.002920217\n",
      "0.0076411986\n",
      "0.003784694\n",
      "0.01913858\n",
      "0.012232448\n",
      "0.0060778135\n",
      "0.030905237\n",
      "0.0005463324\n",
      "0.0095838215\n",
      "0.007144549\n",
      "0.016268596\n",
      "0.011999551\n",
      "0.0048256894\n",
      "0.017938841\n",
      "0.008363566\n",
      "0.0015466023\n",
      "0.0053228354\n",
      "0.050151024\n",
      "0.012365963\n",
      "0.047916714\n",
      "0.0052485103\n",
      "0.0011095479\n",
      "0.008878939\n",
      "0.026899815\n",
      "0.0029922735\n",
      "0.010597774\n",
      "0.0065950877\n",
      "0.0021498727\n",
      "0.011254303\n",
      "0.022856805\n",
      "0.025481079\n",
      "0.009689315\n",
      "0.0074478085\n",
      "0.005482655\n",
      "0.059278212\n",
      "0.0028032626\n",
      "0.0063734287\n",
      "0.0006698554\n",
      "0.015586294\n",
      "0.0046928013\n",
      "0.0066613727\n",
      "0.017453648\n",
      "0.003008427\n",
      "0.001835426\n",
      "0.0644499\n",
      "0.0044050426\n",
      "0.007477023\n",
      "0.0025895091\n",
      "0.031592645\n",
      "0.02398154\n",
      "0.009184322\n",
      "0.000515883\n",
      "0.0052108616\n",
      "0.05156316\n",
      "0.04284702\n",
      "0.017751794\n",
      "0.008032765\n",
      "0.0040246686\n",
      "0.0018064923\n",
      "0.0060886936\n",
      "0.04504068\n",
      "0.054164372\n",
      "0.0028858816\n",
      "0.011544942\n",
      "0.0038275633\n",
      "0.05364021\n",
      "0.005709371\n",
      "0.0009004882\n",
      "0.0033982424\n",
      "0.0067445016\n",
      "0.013001492\n",
      "0.00934009\n",
      "0.007945658\n",
      "0.007921664\n",
      "0.028957786\n",
      "0.004643512\n",
      "0.0013527247\n",
      "0.0049858447\n",
      "0.0025340156\n",
      "0.049249843\n",
      "0.012032573\n",
      "0.011809162\n",
      "0.0016792151\n",
      "0.014656672\n",
      "0.009247877\n",
      "0.0074685793\n",
      "0.021102574\n",
      "0.035525367\n",
      "0.013584161\n",
      "0.0020271146\n",
      "0.0015097979\n",
      "0.021845412\n",
      "0.00049426913\n",
      "0.023378005\n",
      "0.022102518\n",
      "0.0024934534\n",
      "0.04921145\n",
      "0.0009696573\n",
      "0.018084949\n",
      "0.011593687\n",
      "0.024447287\n",
      "0.019937921\n",
      "0.020779513\n",
      "0.001984591\n",
      "0.0073852753\n",
      "0.0082369335\n",
      "0.008861235\n",
      "0.009661081\n",
      "0.0075007062\n",
      "0.011850503\n",
      "0.010784533\n",
      "0.0004134626\n",
      "0.004051563\n",
      "0.016279984\n",
      "0.0031947102\n",
      "0.0033942256\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for i, (images, labels) in enumerate(zip(train_images, train_labels)):\n",
    "        loss = train_job(images, labels)\n",
    "        if i % 20 == 0:\n",
    "            print(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point.save(\"./model/lenet_models_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
